{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 â€“ Analysis of distributed data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data set we already used in the exercise, there is another target attribute: age.\n",
    "Complete the task group A **or** B. Always assess the performance of the corresponding classifier/regressor.\n",
    "\n",
    "**Task group A**\n",
    "1. Build and test a text classifier based on the age of a user according their age classes (0-10, 11-20, 21-30, 31+).\n",
    "\n",
    "2. Build a ML name classifier that classifies the age of a user according their age classes (0-10, 11-20, 21-30, 31+).\n",
    "\n",
    "3. Build a meta classifier that combines the previously built classifiers based on their age classes (0-10, 11-20, 21-30, 31+).\n",
    "\n",
    "**Task group B**\n",
    "1. Build and test a text regressor based on the age of a user according their specific age (regression).\n",
    "\n",
    "2. Build a ML name classifier that classifies the age of a user according their specific age (regression).\n",
    "\n",
    "3. Build a meta classifier that combines the previously built classifiers based on their specific age (regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>**Please make sure:**\n",
    "\n",
    "- each cell (essential step) is commented on with a short sentence\n",
    "- new variables / fields are output in sufficient length (e.g., df.head (10))\n",
    "- each of the tasks is answered with a short written statement\n",
    "\n",
    "This makes the evaluation much easier and, thus, would help us a lot.</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet Score is 57.14%\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB as bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer as countvec\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#reading data\n",
    "data = pd.read_pickle('data/twitterData.pkl')\n",
    "# ignore rows with empty tweets for our text classifier and ignor rows with no value(numbers) for age-column\n",
    "data = data[data['tweets_concatenated'] != '']\n",
    "data = data[np.isfinite(data['age'])]\n",
    "\n",
    "# change target column for classifier.  use a binning\n",
    "bins = [0, 10, 20, 30, 100]\n",
    "labels = [0,23,92,10]\n",
    "data['age_binned'] = pd.cut(data['age'], bins, labels=labels)\n",
    "\n",
    "# create three train splits for all three classifier\n",
    "trainSub, tempData = train_test_split(data, test_size=0.4)\n",
    "trainMeta, test = train_test_split(tempData, test_size=0.4)\n",
    "\n",
    "# only using tweets for text classifier\n",
    "trainSub_tweets = trainSub['tweets_concatenated']\n",
    "trainMeta_tweets = trainMeta['tweets_concatenated']\n",
    "test_tweets = test['tweets_concatenated']\n",
    "\n",
    "\n",
    "# use column age_binned to \n",
    "y_trainSub = trainSub['age_binned']\n",
    "y_trainMeta = trainMeta['age_binned']\n",
    "y_test = test['age_binned']\n",
    "\n",
    "#use countvectorize to transform tweets\n",
    "countvectorizer_tweets = countvec()\n",
    "x_trainSub_tweets = countvectorizer_tweets.fit_transform(trainSub_tweets)\n",
    "x_trainMeta_tweets = countvectorizer_tweets.transform(trainMeta_tweets)\n",
    "x_test_tweets = countvectorizer_tweets.transform(test_tweets)\n",
    "\n",
    "#  using fMultinomialNB model to train and predict\n",
    "bayes_tweets = bayes()\n",
    "bayes_tweets.fit(x_trainSub_tweets, y_trainSub)\n",
    "tweet_score = bayes_tweets.score(x_test_tweets, y_test)\n",
    "tweetScore_text = \"Tweet Score is {:0.2%}\".format(tweet_score)\n",
    "print(tweetScore_text)\n",
    "\n",
    "# save prediction for meta classifier in task3\n",
    "stacked_input1 = pd.Series(bayes_tweets.predict(x_trainMeta_tweets))\n",
    "stacked_input1_test = pd.Series(bayes_tweets.predict(x_test_tweets))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Score is 58.79%\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "# getting the data from  name-column ( train and sub + meta for task 3)\n",
    "trainSub_names = trainSub['name']\n",
    "trainMeta_names = trainMeta['name']\n",
    "test_names = test['name']\n",
    "\n",
    "# using countvectorizer again to transform names\n",
    "cvectorizer_names = countvec()\n",
    "x_trainSub_names = cvectorizer_names.fit_transform(trainSub_names)\n",
    "\n",
    "x_trainMeta_names = cvectorizer_names.transform(trainMeta_names)\n",
    "x_test_names = cvectorizer_names.transform(test_names)\n",
    "\n",
    "# using fMultinomialNB model to train and predict agian\n",
    "bayes_names = bayes()\n",
    "bayes_names.fit(x_trainSub_names, y_trainSub)\n",
    "\n",
    "\n",
    "nameScore2 = bayes_names.score(x_test_names, y_test)\n",
    "nameScore_text2 = \"Name Score is {:0.2%}\".format(nameScore2)\n",
    "print(nameScore_text2)\n",
    "\n",
    "# save prediction for meta classifier in task3\n",
    "stacked_input2 = pd.Series(bayes_names.predict(x_trainMeta_names))\n",
    "stacked_input2_test = pd.Series(bayes_names.predict(x_test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Score is 59.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "# initialize RF classifier\n",
    "forest = RandomForestClassifier()\n",
    "# build a pandas df for training and one for testing\n",
    "# meta training data\n",
    "meta_data_train = {'input1': stacked_input1, 'input2': stacked_input2}\n",
    "meta_data_train = pd.DataFrame(meta_data_train)\n",
    "\n",
    "meta_data_test = {'input1': stacked_input1_test, 'input2': stacked_input2_test}\n",
    "meta_data_test = pd.DataFrame(meta_data_test)\n",
    "\n",
    "# using\n",
    "forest.fit(meta_data_train, y_trainMeta)\n",
    "\n",
    "metaScore = forest.score(meta_data_test, y_test)\n",
    "metaScore_text = \"Meta Score is {:0.2%}\".format(metaScore)\n",
    "\n",
    "print(metaScore_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
